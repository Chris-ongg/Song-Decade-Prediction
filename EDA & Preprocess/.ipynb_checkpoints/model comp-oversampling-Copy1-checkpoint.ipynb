{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "gentle-syndrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "functioning-faculty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import lightgbm as lgbm\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lightweight-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "grave-atlas",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "distant-testament",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_data = pd.read_csv('../data/recleaned_data_stdscle_v2_wartists.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "headed-masters",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>popularity</th>\n",
       "      <th>...</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>key_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.290829</td>\n",
       "      <td>0.343090</td>\n",
       "      <td>-0.586049</td>\n",
       "      <td>-0.276314</td>\n",
       "      <td>-0.578414</td>\n",
       "      <td>5</td>\n",
       "      <td>0.929594</td>\n",
       "      <td>-0.152122</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.635730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.277648</td>\n",
       "      <td>-1.888467</td>\n",
       "      <td>-0.431375</td>\n",
       "      <td>-0.276314</td>\n",
       "      <td>1.401622</td>\n",
       "      <td>8</td>\n",
       "      <td>0.123664</td>\n",
       "      <td>-0.645386</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.184737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.298737</td>\n",
       "      <td>-0.835630</td>\n",
       "      <td>-0.620337</td>\n",
       "      <td>-0.276314</td>\n",
       "      <td>-0.117816</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.630575</td>\n",
       "      <td>-0.608907</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.184737</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.293465</td>\n",
       "      <td>-1.110283</td>\n",
       "      <td>-0.554578</td>\n",
       "      <td>-0.276314</td>\n",
       "      <td>-0.566669</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.304312</td>\n",
       "      <td>-0.388445</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.184737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.027206</td>\n",
       "      <td>-0.732635</td>\n",
       "      <td>-0.434248</td>\n",
       "      <td>3.619065</td>\n",
       "      <td>-0.579976</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.671149</td>\n",
       "      <td>-0.372584</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.184737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration_ms  explicit  instrumentalness  key  \\\n",
       "0      1.290829      0.343090    -0.586049 -0.276314         -0.578414    5   \n",
       "1      1.277648     -1.888467    -0.431375 -0.276314          1.401622    8   \n",
       "2      1.298737     -0.835630    -0.620337 -0.276314         -0.117816    2   \n",
       "3      1.293465     -1.110283    -0.554578 -0.276314         -0.566669    0   \n",
       "4      1.027206     -0.732635    -0.434248  3.619065         -0.579976    0   \n",
       "\n",
       "   liveness  loudness  mode  popularity  ...  key_2  key_3  key_4  key_5  \\\n",
       "0  0.929594 -0.152122     0   -0.635730  ...    0.0    0.0    0.0    1.0   \n",
       "1  0.123664 -0.645386     1   -1.184737  ...    0.0    0.0    0.0    0.0   \n",
       "2 -0.630575 -0.608907     1   -1.184737  ...    1.0    0.0    0.0    0.0   \n",
       "3 -0.304312 -0.388445     1   -1.184737  ...    0.0    0.0    0.0    0.0   \n",
       "4 -0.671149 -0.372584     0   -1.184737  ...    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   key_6  key_7  key_8  key_9  key_10  key_11  \n",
       "0    0.0    0.0    0.0    0.0     0.0     0.0  \n",
       "1    0.0    0.0    1.0    0.0     0.0     0.0  \n",
       "2    0.0    0.0    0.0    0.0     0.0     0.0  \n",
       "3    0.0    0.0    0.0    0.0     0.0     0.0  \n",
       "4    0.0    0.0    0.0    0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df_data.decade\n",
    "\n",
    "df_data = df_data.drop(['decade','year'], axis=1)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "colonial-transcription",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['acousticness', 'danceability', 'duration_ms', 'explicit',\n",
       "       'instrumentalness', 'key', 'liveness', 'loudness', 'mode', 'popularity',\n",
       "       'speechiness', 'tempo', 'valence', 'key_0', 'key_1', 'key_2', 'key_3',\n",
       "       'key_4', 'key_5', 'key_6', 'key_7', 'key_8', 'key_9', 'key_10',\n",
       "       'key_11'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "magnetic-depression",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_data, labels, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "studied-effectiveness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((125683, 25), (125683,), (31421,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-contractor",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "statutory-accident",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cosmetic-intent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((175186, 25), (175186,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled.shape, y_resampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-hacker",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "binding-sarah",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1920       0.24      0.58      0.34      1051\n",
      "        1930       0.37      0.46      0.41      2056\n",
      "        1940       0.39      0.39      0.39      2731\n",
      "        1950       0.42      0.27      0.33      3674\n",
      "        1960       0.41      0.45      0.43      3645\n",
      "        1970       0.37      0.39      0.38      3629\n",
      "        1980       0.39      0.33      0.36      3636\n",
      "        1990       0.39      0.30      0.34      3671\n",
      "        2000       0.33      0.43      0.37      2524\n",
      "        2010       0.64      0.31      0.41      3977\n",
      "        2020       0.20      0.56      0.30       827\n",
      "\n",
      "    accuracy                           0.37     31421\n",
      "   macro avg       0.38      0.41      0.37     31421\n",
      "weighted avg       0.41      0.37      0.37     31421\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#KNN classifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=27)\n",
    "classifier.fit(X_resampled, y_resampled)\n",
    "y_pred = classifier.predict(X_test)\n",
    "# from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-problem",
   "metadata": {},
   "source": [
    "### XGB and LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "australian-basement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1920       0.54      0.60      0.57      1051\n",
      "        1930       0.54      0.50      0.52      2056\n",
      "        1940       0.49      0.55      0.52      2731\n",
      "        1950       0.55      0.44      0.49      3674\n",
      "        1960       0.49      0.55      0.52      3645\n",
      "        1970       0.44      0.43      0.44      3629\n",
      "        1980       0.47      0.42      0.44      3636\n",
      "        1990       0.47      0.47      0.47      3671\n",
      "        2000       0.41      0.49      0.44      2524\n",
      "        2010       0.67      0.56      0.61      3977\n",
      "        2020       0.31      0.55      0.40       827\n",
      "\n",
      "    accuracy                           0.49     31421\n",
      "   macro avg       0.49      0.51      0.49     31421\n",
      "weighted avg       0.50      0.49      0.50     31421\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lgbm = lgbm.LGBMClassifier()\n",
    "\n",
    "model_lgbm.fit(X_resampled, y_resampled)\n",
    "\n",
    "model_lgbm.score(X_test, y_test)\n",
    "\n",
    "y_pred = model_lgbm.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "casual-patio",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4941281308678909"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgbm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hindu-cosmetic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kradk\\anaconda3\\envs\\ml\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:51:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1920       0.57      0.61      0.59      1051\n",
      "        1930       0.53      0.50      0.52      2056\n",
      "        1940       0.51      0.58      0.54      2731\n",
      "        1950       0.55      0.45      0.49      3674\n",
      "        1960       0.50      0.55      0.52      3645\n",
      "        1970       0.44      0.44      0.44      3629\n",
      "        1980       0.47      0.41      0.44      3636\n",
      "        1990       0.47      0.48      0.47      3671\n",
      "        2000       0.42      0.47      0.44      2524\n",
      "        2010       0.67      0.60      0.63      3977\n",
      "        2020       0.33      0.50      0.40       827\n",
      "\n",
      "    accuracy                           0.50     31421\n",
      "   macro avg       0.50      0.51      0.50     31421\n",
      "weighted avg       0.51      0.50      0.50     31421\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_xgb = xgb.XGBClassifier()\n",
    "\n",
    "model_xgb.fit(X_resampled, y_resampled)\n",
    "\n",
    "model_xgb.score(X_test, y_test)\n",
    "\n",
    "y_pred = model_xgb.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-tiger",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "modified-thailand",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   49.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1920       0.61      0.61      0.61      1051\n",
      "        1930       0.58      0.51      0.54      2056\n",
      "        1940       0.50      0.60      0.55      2731\n",
      "        1950       0.56      0.48      0.52      3674\n",
      "        1960       0.49      0.57      0.53      3645\n",
      "        1970       0.44      0.44      0.44      3629\n",
      "        1980       0.46      0.42      0.44      3636\n",
      "        1990       0.47      0.46      0.47      3671\n",
      "        2000       0.44      0.47      0.45      2524\n",
      "        2010       0.67      0.61      0.64      3977\n",
      "        2020       0.37      0.46      0.41       827\n",
      "\n",
      "    accuracy                           0.51     31421\n",
      "   macro avg       0.51      0.51      0.51     31421\n",
      "weighted avg       0.51      0.51      0.51     31421\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(verbose=1)\n",
    "\n",
    "rfc.fit(X_resampled, y_resampled)\n",
    "\n",
    "\n",
    "rfc.score(X_test, y_test)\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-representative",
   "metadata": {},
   "source": [
    "## ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "running-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = ADASYN(sampling_strategy='minority').fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "compound-finance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((139191, 25), (139191,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled.shape, y_resampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-bradley",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "expected-mercy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1920       0.50      0.30      0.38      1051\n",
      "        1930       0.50      0.40      0.44      2056\n",
      "        1940       0.41      0.52      0.46      2731\n",
      "        1950       0.41      0.45      0.43      3674\n",
      "        1960       0.41      0.47      0.44      3645\n",
      "        1970       0.36      0.38      0.37      3629\n",
      "        1980       0.39      0.35      0.37      3636\n",
      "        1990       0.39      0.37      0.38      3671\n",
      "        2000       0.40      0.22      0.28      2524\n",
      "        2010       0.59      0.37      0.45      3977\n",
      "        2020       0.18      0.64      0.29       827\n",
      "\n",
      "    accuracy                           0.40     31421\n",
      "   macro avg       0.41      0.41      0.39     31421\n",
      "weighted avg       0.42      0.40      0.40     31421\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#KNN classifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=27)\n",
    "classifier.fit(X_resampled, y_resampled)\n",
    "y_pred = classifier.predict(X_test)\n",
    "# from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-allen",
   "metadata": {},
   "source": [
    "### XGB and LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "apart-heating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1920       0.72      0.47      0.57      1051\n",
      "        1930       0.63      0.44      0.52      2056\n",
      "        1940       0.49      0.65      0.56      2731\n",
      "        1950       0.54      0.49      0.51      3674\n",
      "        1960       0.50      0.55      0.52      3645\n",
      "        1970       0.45      0.45      0.45      3629\n",
      "        1980       0.47      0.42      0.45      3636\n",
      "        1990       0.45      0.52      0.48      3671\n",
      "        2000       0.48      0.37      0.42      2524\n",
      "        2010       0.64      0.61      0.62      3977\n",
      "        2020       0.29      0.56      0.39       827\n",
      "\n",
      "    accuracy                           0.50     31421\n",
      "   macro avg       0.52      0.50      0.50     31421\n",
      "weighted avg       0.52      0.50      0.50     31421\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lgbm = lgbm.LGBMClassifier()\n",
    "\n",
    "model_lgbm.fit(X_resampled, y_resampled)\n",
    "\n",
    "model_lgbm.score(X_test, y_test)\n",
    "\n",
    "y_pred = model_lgbm.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "toxic-hours",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5044397059291557"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgbm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "moved-bronze",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kradk\\anaconda3\\envs\\ml\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:58:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1920       0.72      0.50      0.59      1051\n",
      "        1930       0.61      0.44      0.51      2056\n",
      "        1940       0.50      0.65      0.56      2731\n",
      "        1950       0.54      0.49      0.52      3674\n",
      "        1960       0.50      0.55      0.52      3645\n",
      "        1970       0.44      0.45      0.44      3629\n",
      "        1980       0.47      0.42      0.44      3636\n",
      "        1990       0.46      0.51      0.48      3671\n",
      "        2000       0.47      0.37      0.41      2524\n",
      "        2010       0.65      0.64      0.64      3977\n",
      "        2020       0.31      0.53      0.39       827\n",
      "\n",
      "    accuracy                           0.51     31421\n",
      "   macro avg       0.51      0.50      0.50     31421\n",
      "weighted avg       0.51      0.51      0.51     31421\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_xgb = xgb.XGBClassifier()\n",
    "\n",
    "model_xgb.fit(X_resampled, y_resampled)\n",
    "\n",
    "model_xgb.score(X_test, y_test)\n",
    "\n",
    "y_pred = model_xgb.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-proposition",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "based-commissioner",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   34.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1920       0.81      0.48      0.60      1051\n",
      "        1930       0.64      0.44      0.52      2056\n",
      "        1940       0.49      0.65      0.56      2731\n",
      "        1950       0.53      0.51      0.52      3674\n",
      "        1960       0.49      0.56      0.52      3645\n",
      "        1970       0.44      0.45      0.44      3629\n",
      "        1980       0.46      0.44      0.45      3636\n",
      "        1990       0.46      0.50      0.48      3671\n",
      "        2000       0.49      0.34      0.40      2524\n",
      "        2010       0.64      0.64      0.64      3977\n",
      "        2020       0.34      0.50      0.41       827\n",
      "\n",
      "    accuracy                           0.51     31421\n",
      "   macro avg       0.53      0.50      0.50     31421\n",
      "weighted avg       0.52      0.51      0.51     31421\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(verbose=1)\n",
    "\n",
    "rfc.fit(X_resampled, y_resampled)\n",
    "\n",
    "\n",
    "rfc.score(X_test, y_test)\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
